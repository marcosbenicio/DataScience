{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import trim_mean\n",
    "from statsmodels import robust\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sets path\n",
    "AIRLINE_STATS_CSV = 'Data/airline_stats.csv'\n",
    "KC_TAX_CSV =  'Data/kc_tax.csv.gz'\n",
    "LC_LOANS_CSV =  'Data/lc_loans.csv'\n",
    "AIRPORT_DELAYS_CSV =  'Data/dfw_airline.csv'\n",
    "SP500_DATA_CSV = 'Data/sp500_data.csv.gz'\n",
    "SP500_SECTORS_CSV = 'Data/sp500_sectors.csv'\n",
    "STATE_CSV = 'Data/state.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printest(args, value):\n",
    "    return print( \"{} : \\n {} \\n\".format(args, value) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "      <th>Murder.Rate</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>5.7</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>710231</td>\n",
       "      <td>5.6</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6392017</td>\n",
       "      <td>4.7</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Population  Murder.Rate Abbreviation\n",
       "0  Alabama     4779736          5.7           AL\n",
       "1   Alaska      710231          5.6           AK\n",
       "2  Arizona     6392017          4.7           AZ"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = pd.read_csv(STATE_CSV)\n",
    "state.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Location\n",
    "\n",
    "Variables containing measured or count data can often possess thousands of unique values. An essential part of data exploration involves identifying a \"representative value\" for each feature - a value that suggests where the majority of the data points tend to cluster (i.e., their central tendency)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean**\n",
    "\n",
    "The mean, often referred to as the average, is a measure of the central tendency of a dataset. It is calculated by adding all the values in the dataset and then dividing by the total number of values.\n",
    "\n",
    "$$\\mu = \\frac{1}{n}\\sum_{i = 1}^{n} x_i $$\n",
    "\n",
    "Here, $x_i$ represents each individual data point, and $n$ is the total number of observations.\n",
    "\n",
    "The mean provides a useful summary of the data's central location, but it is <mark>sensitive to extreme values (outliers)</mark>.\n",
    "\n",
    "**Trimmed (Truncated) Mean**\n",
    "\n",
    "Is a modified version of the mean. It's computed by first sorting the data values, then excluding a fixed number of values from both ends of the sorted list, and finally, taking the average of the remaining data points. This approach mitigates the impact of outliers and can provide a <mark>more representative 'central value' when dealing with skewed data </mark>.\n",
    "\n",
    "The formula to calculate the trimmed mean, omitting $p$ smallest and largest values, is:\n",
    "\n",
    "$$\\mu_t = \\frac{1}{n-2p}\\sum_{i = p+1}^{n-p} x_i $$\n",
    "\n",
    "Here, $n$ is the total number of observations, $p$ is the number of observations discarded from each end, and $x_i$ represents each individual data point that is included in the trimmed mean calculation.\n",
    "\n",
    "**Weighted Mean**\n",
    "\n",
    "Is a generalization of the arithmetic mean that enables us to assign specific weights or importance to each data point. In calculating the weighted mean, each data point is multiplied by a predetermined weight before summation. The sum of these products is then divided by the total of the weights, not just the number of data points. This allows the weighted mean to reflect the relative contribution of each point to the total.\n",
    "\n",
    "$$\\mu_w= \\frac{1}{\\sum_{i = 1}^{n} w_i}\\sum_{i = 1}^{n} w_ix_i $$\n",
    "\n",
    "This measure is particularly useful when some data points are intrinsically more significant than others, or when the data collected does not equally represent the different groups that we are interested in measuring.\n",
    "\n",
    "**Median**\n",
    "\n",
    "It is the value that separates the highest half of a data set from the lowest half. In other words, the median is the middle point of a data set. Unlike the mean, the median is not affected by outliers or skewed data. This makes the median a more robust measure than the mean when dealing with data that contains extreme values or is not symmetrically distributed.\n",
    "\n",
    "To compute the median, the data set must first be sorted in ascending order. If the number of observations, $n$, is odd, the median is the value at position $(n+1)/2$. If $n$ is even, the median is the average of the values at positions $n/2$ and $n/2 + 1$.\n",
    "\n",
    "The median gives a better measure of central tendency when data is skewed or when there are extreme outliers. However, in symmetric distributions with no outliers, the mean and the median are often the same or close to each other.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The median, while robust to extreme values, only considers the middle value (or the average of the two middle values in case of an even number of observations), effectively discarding the rest of the data. The mean, on the other hand, considers all data points but is heavily influenced by outliers or extreme values.\n",
    "\n",
    "The trimmed mean attempts to balance this by removing a certain percentage of the largest and smallest values in the dataset, and then calculating the mean of the remaining data. This makes it robust to outliers (like the median) while still utilizing more data than the median does.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data set containing population and murder\n",
    "rates (in units of murders per 100,000 people per year) for each US state (2010\n",
    "Census). Let's compute the mean, trimmed mean, and median for the population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "state.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "printest('Mean Population',state['Population'].mean())\n",
    "printest('Truncated Mean Population',trim_mean(state['Population'], 0.1) )\n",
    "printest('Median Population',state['Population'].median())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the truncated mean and the median provide more \"typical\" population values than the mean, as they are less influenced by any extreme population numbers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates of Variability\n",
    "\n",
    "Variability, also referred to as dispersion, measures whether the data values are tightly clustered or spread out from the central value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance and Standart Deviation**\n",
    "The variance is an average of the squared deviations, \n",
    "\n",
    "$$s^2 = \\frac{1}{n}\\sum_{i = 1}^{n}(x_i - \\mu)^2 $$\n",
    "\n",
    "and the standard deviation is the square root of the variance:\n",
    "\n",
    "$$s = \\sqrt{\\frac{1}{n}\\sum_{i = 1}^{n}(x_i - \\mu)^2} $$\n",
    "\n",
    "The variance and standard deviation are especially sensitive to outliers since they are based on the squared deviations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates Based on Percentiles\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The interquartile range (IQR)**\n",
    "\n",
    "IQR is a measure of variability, based on dividing a dataset into quartiles. It is defined as the difference between the third quartile ($Q_3$) and the first quartile ($Q_1$). \n",
    "\n",
    "A quartile divides data into four equal parts, each comprising 25% of the data. $Q_1$ represents the 25th percentile of the data, meaning 25% of data points are less than or equal to this value. $Q_3$ represents the 75th percentile, implying that 75% of data points are less than or equal to this value.\n",
    "\n",
    "The IQR gives a sense of how spread out the values in a dataset are and is a robust measure of dispersion that is not influenced by outliers. It is often used in exploratory data analysis to detect outliers and to summarize a large dataset.\n",
    "\n",
    "- To calculate the IQR\n",
    "  1. **Ordering the Data**: First, arrange the data in increasing or decreasing order. This step is crucial as the IQR depends on values at specific positions in the ordered dataset.\n",
    "  2. **Determining Quartiles:**  identify the first quartile ($Q_1$) and the third quartile ($Q_3$). \n",
    "      - $Q_1$ is the median (middle value) of the first half of the sorted data.\n",
    "      - $Q_3$ is the median of the second half of the sorted data.\n",
    "  3. **Calculating IQR:** Finally, calculate the IQR by subtracting $Q_1$ from $Q_3$. This difference represents the range of the central 50% of the dataset, hence giving a robust measure of dispersion that is not influenced by outliers or extreme values.\n",
    "\n",
    "\n",
    "- For example, if a dataset has the following values: $[3, 5, 7, 8, 9, 11, 14, 15, 16, 17]$, \n",
    "  -  $Q_1$ would be 8 (median of $[3, 5, 7, 8]$), \n",
    "  -  $Q_3$ would be 16 (median of $[14, 15, 16, 17]$), \n",
    "  -   IQR would be $16 - 8 = 8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "printest('Standard Deviation Population:',state['Population'].std())\n",
    "printest('IQR Population',state['Population'].quantile(0.75) - state['Population'].quantile(0.25))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles and Boxplots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "percentages = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "df = pd.DataFrame(state['Murder.Rate'].quantile(percentages))\n",
    "df.index = [f'{p * 100}%' for p in percentages]\n",
    "print(df.transpose())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is 4 murders per 100,000 people, although there is quite a bit of variability:\n",
    "the 5th percentile is only 1.6 and the 95th percentile is 6.51."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box Plot**\n",
    "\n",
    "A box plot, also known as a box-and-whisker plot, is a graphical representation of statistical data that illustrates a dataset's key quantiles and potential outliers.\n",
    "\n",
    "- The box represents the interquartile range (IQR), which is the range between the first quartile (25th percentile) and the third quartile (75th percentile). The line inside the box marks the median (50th percentile).\n",
    "  \n",
    "- The whiskers extend from the box to show the overall spread of the data, typically 1.5 times the IQR.\n",
    "  - The lower whisker point is calculated as $Q_1 - 1.5 IQR$\n",
    "  - The upper whisker point is calculated as $Q_3 + 1.5 IQR$\n",
    "  \n",
    "- Any dots or other markers beyond the whiskers indicate potential outliers.\n",
    "The box plot provides a summary of a dataset's distribution and is particularly useful for comparing distributions across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.boxplot(state['Population']/10e5, widths = 0.7, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='black'),\n",
    "            capprops=dict(color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            flierprops=dict(color='red', markeredgecolor='red'),\n",
    "            medianprops=dict(color='black'),\n",
    "            )\n",
    "q1 = np.percentile(state['Population']/10e5, 25)\n",
    "q2 = np.percentile(state['Population']/10e5, 50)\n",
    "q3 = np.percentile(state['Population']/10e5, 75)\n",
    "iqr = q3-q1\n",
    "\n",
    "plt.text(1.35, q1, '$Q_1$', va='center',color= 'navy', fontsize = 12)\n",
    "plt.text(1.35, q2, '$Q_2$ (Median)', va='center', color= 'navy', fontsize = 12)\n",
    "plt.text(1.35, q3, '$Q_3$', va='center', color= 'navy', fontsize = 12)\n",
    "plt.text(1.1, q3+1.5*iqr, '$Q_3 + 1.5IQR$', va='center',color= 'navy', fontsize = 12)\n",
    "\n",
    "# q1-1.5*iqr = 0  because the feature has no negative values\n",
    "plt.text(1.1, -0.5, '$Q_1 - 1.5IQR$', va='center',color= 'navy', fontsize = 12)\n",
    "\n",
    "plt.ylabel('Population (millions)')\n",
    "plt.title('Boxplot of Population')\n",
    "plt.xticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(state['Population']/10e5, bins = 10, edgecolor = 'navy', color = 'lightblue')\n",
    "\n",
    "plt.xlabel('Population (millions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(0,40, 10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Plots\n",
    "\n",
    "Related to the histogram is a density plot, which shows the distribution of data values\n",
    "as a continuous line. Density plot can be thought of as a smoothed histogram,\n",
    "although it is typically computed directly from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(state['Population']/10e5, bins = 10, color = 'blue', kde=True)\n",
    "plt.xlabel('Population (millions)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(0,40, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Exploratory data analysis in many modeling projects (whether in data science or in\n",
    "research) involves examining correlation among predictors, and between predictors\n",
    "and a target variable. Variables X and Y (each with measured data) are said to be positively\n",
    "correlated if high values of X go with high values of Y, and low values of X go\n",
    "with low values of Y. If high values of X go with low values of Y, and vice versa, the\n",
    "variables are negatively correlated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Two or More Variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0743c798041383927c03f3bae5eca888e94e4777f716cdd511cdff96fbdedc02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
