{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mutual_info_score, accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printest(args, value):\n",
    "    return print( \"{} : \\n {} \\n\".format(args, value) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - data preparation and model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn prediction is about identifying customers who are likely to cancel their contracts soon. If the company can do that, it can offer discounts on these services in an effort to keep the users. Here we use the dataset of churn prediction for a telecom company.\n",
    "\n",
    "- A value of 0 indicates that the customer did not churn (they stayed with the service).\n",
    "- A value of 1 indicates that the customer did churn (they left the service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Convert 'TotalCharges' to numeric, replace non-numeric with NaN\n",
    "df['TotalCharges'] = pd.to_numeric(df.TotalCharges, errors='coerce')\n",
    "# Fill NaN values with zero\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(0)\n",
    "\n",
    "# lowering columns name and replace spaces by _\n",
    "df.columns  = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "\n",
    "# boolean mask to select columns with object type (string)\n",
    "obj_mask = df.dtypes == 'object' \n",
    "obj_columns = list(df.dtypes[obj_mask].index)\n",
    "\n",
    "# lowering rows strings and replace spaces by _\n",
    "for col in obj_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "# turn 'no' into 0 and 'yes' into 1\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train, test, validation\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
    "\n",
    "# save target values\n",
    "y_train = df_train['churn'].values\n",
    "y_val = df_val['churn'].values\n",
    "\n",
    "# take out the target values from the dataframe\n",
    "del df_train['churn']\n",
    "del df_val['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical : \n",
      " ['gender', 'partner', 'dependents', 'phoneservice', 'multiplelines', 'internetservice', 'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport', 'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling', 'paymentmethod', 'seniorcitizen'] \n",
      "\n",
      "numerical : \n",
      " ['tenure', 'monthlycharges', 'totalcharges'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All categorical columns except 'customerid'\n",
    "categorical_mask = df_train.dtypes == 'object'\n",
    "categorical = list(df_train.dtypes[categorical_mask].index)\n",
    "categorical.remove('customerid') \n",
    "\n",
    "# Manually add 'seniorcitizen' because it's an int boolean (0 or 1)\n",
    "categorical.append('seniorcitizen')\n",
    "printest('categorical', categorical)\n",
    "\n",
    "# All numerical columns except 'seniorcitizen' because it's an int boolean\n",
    "numerical_mask = df_train.dtypes != 'object'\n",
    "numerical = list(df_train.dtypes[numerical_mask].index)\n",
    "numerical.remove('seniorcitizen')\n",
    "printest('numerical', numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1, solver='liblinear')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform dataframe to dict\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "# One-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(train_dict)\n",
    "X_train = dv.transform(train_dict)\n",
    "\n",
    "# Model train for all relevant features\n",
    "model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob Not churn| Prob Churn : \n",
      " [[0.76508893 0.23491107]\n",
      " [0.7311339  0.2688661 ]\n",
      " [0.6805482  0.3194518 ]\n",
      " ...\n",
      " [0.94274725 0.05725275]\n",
      " [0.38476961 0.61523039]\n",
      " [0.93872737 0.06127263]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# validate the model\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "y_pred = model.predict_proba(X_val)\n",
    "printest('Prob Not churn| Prob Churn',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob Not churn| Prob Churn : \n",
      " [[0.76508893 0.23491107]\n",
      " [0.7311339  0.2688661 ]\n",
      " [0.6805482  0.3194518 ]\n",
      " ...\n",
      " [0.94274725 0.05725275]\n",
      " [0.38476961 0.61523039]\n",
      " [0.93872737 0.06127263]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training the model for a subset of features\n",
    "small_subset = ['contract', 'tenure', 'totalcharges']\n",
    "train_dict_small = df_train[small_subset].to_dict(orient='records')\n",
    "dv_small = DictVectorizer(sparse=False)\n",
    "dv_small.fit(train_dict_small)\n",
    "\n",
    "X_small_train = dv_small.transform(train_dict_small)\n",
    "\n",
    "model_small = LogisticRegression(solver='liblinear', random_state=1)\n",
    "model_small.fit(X_small_train, y_train)\n",
    "\n",
    "val_dict_small = df_val[small_subset].to_dict(orient='records')\n",
    "X_small_val = dv_small.transform(val_dict_small)\n",
    "\n",
    "y_pred_small = model_small.predict_proba(X_small_val)\n",
    "printest('Prob Not churn| Prob Churn',y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Evaluation metrics serve as a critical tool for quantifying the performance of a model. They function by assessing the model's predictions against the actual observed values. This comparison yields a measurement that indicates the model's predictive accuracy. Therefore, evaluation metrics provide an essential insight into the model's proficiency and its ability to generalize to unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of a binary classification model is determined by the proportion of predictions it correctly makes relative to the total number of predictions. In mathematical terms, this can be represented as:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{correct}}{\\text{total}} = \\frac{1491}{1860} = 80\\%$$\n",
    "\n",
    "This metric provides valuable insight into the model's performance. By tallying the instances where our model's predictions align with the actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Accuracy : \n",
      " 0.8016129032258065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy explicitly\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "# probability threshold\n",
    "churn = y_pred >= 0.5\n",
    "correct = (y_val == churn).sum()\n",
    "total = len(y_val)\n",
    "accuracy = correct/total\n",
    "printest('Full Model Accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small Model Accuracy : \n",
      " 0.7672043010752688 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy explicitly\n",
    "y_pred_small = model_small.predict_proba(X_small_val)[:, 1]\n",
    "# probability threshold\n",
    "churn = y_pred_small >= 0.5\n",
    "correct = (y_val == churn).sum()\n",
    "total = len(y_val)\n",
    "accuracy = correct/total\n",
    "printest('Small Model Accuracy', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the optimal threshold, we can iteratively calculate the accuracy for a range of potential threshold values. This process allows us to assess the performance of our model at various decision boundaries, thereby enabling us to select the threshold that yields the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.261290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>0.501075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.594624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.640323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>0.689785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.729570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.754839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.767204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>0.781720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.795161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.801613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>0.790323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>0.789785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>0.788172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>0.773656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.752151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.738710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>0.738710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.738710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.738710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy\n",
       "threshold          \n",
       "0.00       0.261290\n",
       "0.05       0.501075\n",
       "0.10       0.594624\n",
       "0.15       0.640323\n",
       "0.20       0.689785\n",
       "0.25       0.729570\n",
       "0.30       0.754839\n",
       "0.35       0.767204\n",
       "0.40       0.781720\n",
       "0.45       0.795161\n",
       "0.50       0.801613\n",
       "0.55       0.790323\n",
       "0.60       0.789785\n",
       "0.65       0.788172\n",
       "0.70       0.773656\n",
       "0.75       0.752151\n",
       "0.80       0.741935\n",
       "0.85       0.738710\n",
       "0.90       0.738710\n",
       "0.95       0.738710\n",
       "1.00       0.738710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 21)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for t in thresholds:\n",
    "    acc = accuracy_score(y_val, y_pred >= t)\n",
    "    accuracies.append(acc)\n",
    "    #print('%0.2f %0.3f' % (t, acc))\n",
    "\n",
    "# Create a dictionary\n",
    "data = {'threshold': thresholds, 'accuracy': accuracies}\n",
    "\n",
    "# Create DataFrame\n",
    "df_acc = pd.DataFrame(data)\n",
    "\n",
    "# Print DataFrame\n",
    "display(df_acc.set_index('threshold'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, using the threshold of 0.5 gives us the best accuracy. Typically, 0.5 is a good\n",
    "threshold value to start with. To make it more visual, we can use Matplotlib to create a plot that shows how accuracy changes depending on the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(df_acc['threshold'].values, df_acc['accuracy'].values, color='black')\n",
    "\n",
    "plt.title('Threshold vs Accuracy')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xticks(np.linspace(0, 1, 11))\n",
    "\n",
    "# plt.savefig('04_threshold_accuracy.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy baseline\n",
    "\n",
    "Establishing a baseline is an important step in evaluating the performance of our predictive models. For this purpose, we often use a dummy model — a simple construct which consistently predicts the same outcome, regardless of the input features. In our case, it consistently outputs 'False'. \n",
    "\n",
    "By comparing the performance of our complex models against this baseline, we gain a clear understanding of their incremental improvement in predictive accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model Accuracy : \n",
      " 0.7672043010752688 \n",
      "\n",
      "Small Model Accuracy : \n",
      " 0.7672043010752688 \n",
      "\n",
      "Baseline accuracy : \n",
      " 0.7387096774193549 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dummy model that outputs only False\n",
    "size_val = len(y_val)\n",
    "baseline = np.repeat(False, size_val)\n",
    "\n",
    "\n",
    "printest('Full Model Accuracy', accuracy)\n",
    "printest('Small Model Accuracy', accuracy)\n",
    "printest('Baseline accuracy', accuracy_score(baseline, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the performance of our models, we notice that the smaller model surpasses the naive baseline by a marginal 2%, while the larger model achieves a slightly better improvement of 6%. According to accuracy metrics, our model only offers a marginal improvement over a rudimentary model that categorizes all customers as non-churning and makes no effort to retain them. \n",
    "\n",
    "This phenomenon often arises in scenarios where there is class imbalance, a condition wherein one class outnumbers the other. This imbalance is indeed apparent in our dataset, where 74% of customers didn't churn while only 26% did. For this we need another metric that validate the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix and Measures\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix for multiple classes**\n",
    "\n",
    "The accuracy is a global measure in that it does not explicitly consider the classes that contribute to the error. A more detailed understanding can be achieved by noting the agreement and disagreement for specific classes between the actual and predicted labels in the validation or test set. \n",
    "\n",
    "Consider a typical dataset for the validation points with multiple classes,\n",
    "$$\\mathbf{D} =\n",
    "\\left( \\begin{array}{c|cccc|c}\n",
    "~    &X_{0}&X_{1}&\\cdots & X_{d}  & Y\\\\\n",
    "\\hline\n",
    "\\mathbf{x}_{1} &1& x_{11}& \\cdots&x_{1d}&y_1 \\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\n",
    "\\mathbf{x}_{n}&1&x_{n1}&\\cdots&x_{nd}&y_n\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "The target values, denoted as $\\mathbf{Y} = (y_1, \\cdots, y_i, \\cdots, y_n)$, are not binary; instead, each $y_i \\in \\{c_1, \\cdots, c_k\\}$ represents one of $k$ class labels. Here, $\\mathcal{D}= \\{\\mathbf{D}_1,\\mathbf{D}_2, \\cdots,\\mathbf{D}_k\\}$ denotes the division of validation data according to their true class labels $y$.\n",
    "\n",
    "The $j^{th}$ split for the target values $y_i$ on the validation set is defined as:\n",
    "\n",
    "$$\\mathbf{D}_j = \\{\\mathbf{x}_i | y_i = c_j\\}$$\n",
    "\n",
    "with $n_i = |\\mathbf{D}_i|$ as the count of the true class $c_i$ within the validation set.\n",
    "\n",
    "Another division is conducted based on the predicted values from the validation set, forming $\\mathcal{R} = \\{\\mathbf{R}_1, \\mathbf{R}_2, \\cdots, \\mathbf{R}_k\\}$. This denotes that the $j^{th}$ partition for the predicted target value $\\hat{y}_i$ on the validation set is:\n",
    "\n",
    "$$\\mathbf{R}_j = \\{\\mathbf{x}_i | \\hat{y}_i = c_j\\}$$\n",
    "\n",
    "and $m_i = |\\mathbf{R}_i|$ represents the quantity of the predicted class $c_j$.\n",
    "\n",
    "The divisions $\\mathcal{R}$ and $\\mathcal{D}$ yield a $k \\times k$ matrix $\\mathbf{N}$, better known as a confusion matrix. This matrix illustrates the intersections of each partition from the sets $\\mathcal{R}$ and $\\mathcal{D}$:\n",
    "\n",
    "$$\\mathbf{N}(i,j) = n_{ij} = |\\mathbf{R}_i \\cap \\mathbf{D}_j |  = |\\{\\mathbf{x}_a \\in \\mathbf{D}| \\hat{y}_a = c_j ~~\\text{and} ~~ y_a = c_i \\}|$$\n",
    "\n",
    "For $1\\leq i$, $j \\leq k$, $n_{ij}$ represents the count of instances with a predicted class of $c_i$ and an actual label of $c_j$. These matrix values account for the total instances in each intersection. The matrix is presented as:\n",
    "\n",
    "$$\\mathbf{N} =\n",
    "\\left( \\begin{array}{c|cccc}\n",
    "~  y_{i} |~~\\hat{y}_i  &c_{1}&c_{2}&\\cdots & c_{k} \\\\\n",
    "\\hline\n",
    "{c}_{1} &n_{11}& n_{12}& \\cdots&n_{1k} \\\\\n",
    "{c}_{2} &n_{21}& n_{22}& \\cdots&n_{2k} \\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\\\\n",
    "c_{k}&n_{k1}&n_{k2}&\\cdots&n_{kk}\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "The diagonal elements, $n_{ii} = |\\mathbf{R}_i \\cap \\mathbf{D}_i|$ (for $1\\leq i \\leq k$), denote instances where the classifier correctly identifies the true label $c_i$. The size of $\\mathbf{R}_i$ (the set of instances predicted as class $c_i$) and $\\mathbf{D}i$ (the set of instances that are truly class $c_i$) and their relationship with $n_{ii}$ can provide further insights:\n",
    "\n",
    "- If the size of $\\mathbf{R}_i$ is equal to the size of $\\mathbf{D}_i$, and $n_{ii}$ equals to the size of these sets, then the classifier has made perfect predictions for class $c_i$.\n",
    "\n",
    "- If the size of $\\mathbf{R}_i$ is larger than the size of $\\mathbf{D}_i$, it means that the classifier has predicted more instances as class $c_i$ than there actually are.\n",
    "\n",
    "- If the size of $\\mathbf{R}_i$ is smaller than the size of $\\mathbf{D}_i$, it means that the classifier has predicted fewer instances as class $c_i$ than there actually are.\n",
    "\n",
    "The off-diagonal elements, $n_{ij} = |\\mathbf{R}_i \\cap \\mathbf{D}_j|$ where $i \\neq j$, represent instances where the classifier's predictions and the true labels diverge. If $n_{ij}$ is non-zero, it signifies that there are instances where the classifier predicted class $c_i$ while the true class was $c_j$, indicating a misclassification error.\n",
    "\n",
    "- If the size of $\\mathbf{R}_i$ is larger than the size of $\\mathbf{D}_j$, it suggests that the classifier has over-predicted instances as class $c_i$ when they are actually class $c_j$. \n",
    "\n",
    "- If the size of $\\mathbf{R}_i$ is smaller than the size of $\\mathbf{D}_j$, it implies that the classifier has under-predicted instances as class $c_i$ when they are actually class $c_j$. \n",
    "\n",
    "To measure the quality of the classifier, we can calculate rates with respect to the sizes of each subset and their intersection:\n",
    "\n",
    "**Accuracy/Precision**\n",
    "\n",
    "The precision for a specific class $c_i$ is defined as the proportion of accurate predictions out of all points predicted to belong to class $c_i$:\n",
    "\n",
    "$$\\text{acc}_i = \\text{prec}_i= \\frac{|\\mathbf{R}_i \\cap \\mathbf{D}_i | }{|\\mathbf{R}_i|}  = \\frac{n_{ii}}{m_i}$$\n",
    "\n",
    "Here, $m_i$ is the total number of predictions for class $c_i$, and $n_{ii}$ represents instances where the classifier correctly identifies the true label $c_i$. A high precision for class $c_i$ indicates a more effective classifier.\n",
    "\n",
    "**Covarage/Recall**\n",
    "\n",
    "Recall, also known as coverage, for class $c_i$ is determined by the ratio of correct predictions to all points actually in class $c_i$:\n",
    "\n",
    "$$\\text{coverage}_i= \\text{recall}_i = \\frac{|\\mathbf{R}_i \\cap \\mathbf{D}_i | }{|\\mathbf{D}_i|} =  \\frac{n_{ii}}{n_i}$$\n",
    "\n",
    "Here, $n_i$ denotes the number of instances in class $c_i$. A high recall for class $c_i$ implies a more capable classifier.\n",
    "\n",
    "**F-Measures**\n",
    "\n",
    "Precision and recall often present a trade-off when assessing classifier performance. The F-measure seeks to balance these values by calculating their harmonic mean for class $c_i$:\n",
    "\n",
    "- If $\\text{recall}_i = 1$, the classifier predicts all validation points as belonging to class $c_i$. However, this will usually result in a low precision $\\text{prec}_i$.\n",
    "\n",
    "- If $\\text{prec}_i$ is very high because the classifier predicts only a few points as $c_i$, the recall $\\text{recall}_i$ is likely to be low.\n",
    "\n",
    "The F-measure seeks to harmonize the precision and recall values by calculating their harmonic mean for class $c_i$:\n",
    "\n",
    "$$F_i = \\frac{2}{\\frac{1}{\\text{prec}_i} + \\frac{1}{\\text{recall}_i}} = \\frac{2\\text{prec}_i \\text{recall}_i}{\\text{prec}_i + \\text{recall}_i} = \\frac{2n_{ii}}{n_i + m_i}$$\n",
    "\n",
    "The higher the $F_i$ value, the more effective the classifier for the specific class.\n",
    "\n",
    "The overall F- measure for the classifier is the mean of the class-specific values:\n",
    "\n",
    "$$F = \\frac{1}{k}\\sum^r_{i=1}F_i$$\n",
    "\n",
    "For perfect classifier, the maximum value of F measure is 1.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix for Binary classes**\n",
    "\n",
    "After considering a general case of multiple classes, we now turn our focus to the specific instance of binary classification. In such a scenario, where $k = 2$, we designate $c_0 = c_{~-}$ as the positive class and $c_1 = c_{~+}$ as the negative class. The target values are represented as $\\mathbf{Y} = (c_{~-}, c_{~+})$. Consequently, the sets of true values are denoted as $\\mathcal{D} = \\{\\mathbf{D}_{~-}, \\mathbf{D}_{~+}\\}$, and the predicted values are indicated as $\\mathcal{R} = \\{\\mathbf{R}_{~-}, \\mathbf{R}_{~+}\\} $. The divisions $\\mathcal{R}$ and $\\mathcal{D}$ form a $2 \\times 2$ matrix, as presented below:\n",
    "\n",
    "$$\\mathbf{N} =\n",
    "\\left( \\begin{array}{c|cc}\n",
    "~  y_{i} |~~\\hat{y}_i  &c_{~-}& c_{~+} \\\\\n",
    "\\hline\n",
    "{c}_{~-} &n_{00}& n_{01}&  \\\\\n",
    "{c}_{~+} &n_{10}& n_{11}&  \\\\\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "Each entry of the matrix corresponds to the size of the intersection of the subsets $n_{ij} = |\\mathbf{R}_i \\cap \\mathbf{D}_j |$ for $i,j = \\{-,+\\} = \\{0, 1\\}$. In the context of binary classification, each entry of the matrix is given a specific name:\n",
    "\n",
    "\n",
    "- **True Negatives (TN)**: The number of points that the classifier correctly predicts as negative:\n",
    "\n",
    "  $$\\text{TN} = n_{00} = |\\mathbf{R}_{~-} \\cap \\mathbf{D}_{~-} | = |\\{\\mathbf{x}_i|\\hat{y}_i = y_i = c_{~-}\\}|$$\n",
    "\n",
    "- **False Negatives (FN)**: The number of points the classifier predicts to be in the negative class, wich in fact belongs to the positive class: \n",
    "\n",
    "  $$\\text{FN} = n_{10} = |\\mathbf{R}_{~-} \\cap \\mathbf{D}_{~+} | = |\\{\\mathbf{x}_i|\\hat{y}_i = c_{~-}~~\\text{and}~~ y_i = c_{~+}\\}|$$\n",
    "\n",
    "- **False Positives (FP)**:The number of points the classifier predicts to be positive, wich in fact belong to the negative class:\n",
    "\n",
    "  $$\\text{FP} = n_{01} = |\\mathbf{R}_{~+} \\cap \\mathbf{D}_{~-} | = |\\{\\mathbf{x}_i|\\hat{y}_i = c_{~+}~~\\text{and}~~ y_i = c_{~-}\\}|$$\n",
    " \n",
    "\n",
    "\n",
    "- **True Positives (TP)**: the number of points that the classifier correctly predicts as positive:\n",
    "  \n",
    "  $$\\text{TP} = n_{11} = |\\mathbf{R}_{~+} \\cap \\mathbf{D}_{~+} | = |\\{\\mathbf{x}_i|\\hat{y}_i = y_i = c_{~+}\\}|$$\n",
    "As an example, let's consider a dataset of customers and their 'churn' status. Here, $c_{~-}$ represents no churn and $c_{~+}$ indicates churn. Using a validation dataset, we can distribute all customers across the categories defined above.\n",
    "\n",
    "<center><img src = \"Images/sets_confusion_matrix.png\" width=\"500\" height=\"400\"/></center>\n",
    "\n",
    "\n",
    "**Global Measures**\n",
    "\n",
    "Global measures of the classifier performance\n",
    "\n",
    "- **Error rate**: The proportion of incorrect predictions:\n",
    "\n",
    "$$\\text{Error Rate} = \\frac{\\text{FP} + \\text{FN}}{n}$$\n",
    "\n",
    "- **Accuracy**: The proportion of correct predictions:\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{n}$$\n",
    "\n",
    "where $n$ is the total points in the validation dataset.\n",
    "\n",
    "**Class Specific Measures**\n",
    "\n",
    "- **Precision**: The ratio of correct predictions to all points predicted to belong to the positive or negative class\n",
    "\n",
    " $$\\text{prec}_i = \\frac{n_{ii}}{m_i} = \\left\\{ \\begin{array}{ll} \n",
    "\\frac{n_{00}}{m_{~-}} = \\frac{\\text{TN}}{\\text{TN}+\\text{FN}} \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{n_{11}}{m_{~+}} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}\n",
    "\\end{array}\\right.$$\n",
    "\n",
    " where $m_i = |\\mathbf{R}_i|$ is the number of points predicted having class $c_i$\n",
    "\n",
    "- **Recall**: The ratio of correct predictions out of all points in the positive or negative class.\n",
    "  \n",
    "  - **True Negative Rate (Specificity)**: \n",
    "\n",
    "  $$\\text{recall}_{~-} = \\text{sensitivity}= \\frac{n_{00}}{n_{~-}} =\\frac{\\text{TN}}{\\text{TN} +\\text{FP}}  $$\n",
    "\n",
    "   where $n_{~-} = |\\mathbf{D}_{~-}|$ is the size of the negative class.\n",
    "\n",
    "  - **True Positive Rate (Sensitivity)**:\n",
    "\n",
    "  $$\\text{recall}_{~+} = \\text{sensitivity} = \\frac{n_{11}}{n_{~+}}  = \\frac{\\text{TP}}{\\text{TP} +\\text{FN}} $$\n",
    "\n",
    "  where $n_{~+} = |\\mathbf{D}_{~+}|$  is the size of the positive class.\n",
    "\n",
    "- **$1 -$ Recall** : The ratio of incorrect predictions to all points in the positive or negative class.\n",
    "\n",
    "  - **False Negative Rate (FNR)**:\n",
    "    \n",
    "    $$1- \\text{sensitivity} = \\frac{n_{10}}{n_{~-}} =  \\frac{\\text{FN}}{\\text{TN} +\\text{FP}}$$\n",
    "    \n",
    "  - **False Positive Rate (FPR)**:\n",
    "\n",
    "    $$1- \\text{specificity} = \\frac{ n_{01} } {n_{~+}} =  \\frac{ \\text{FP} }{\\text{TP} +\\text{FN} }$$\n",
    "\n",
    "\n",
    "Now let's translate all these to python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[1202  172]\n",
      " [ 197  289]] \n",
      "\n",
      "Confusion matrix % : \n",
      " [[0.646 0.092]\n",
      " [0.106 0.155]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# & stands as the intersection of the subsets\n",
    "predict_churn = (y_pred >= 0.5)\n",
    "predict_no_churn = (y_pred < 0.5)\n",
    "actual_churn = (y_val == 1)\n",
    "actual_no_churn = (y_val == 0)\n",
    "\n",
    "true_positive = (predict_churn & actual_churn).sum()\n",
    "false_positive = (predict_churn & actual_no_churn).sum()\n",
    "false_negative = (predict_no_churn & actual_churn).sum()\n",
    "true_negative = (predict_no_churn  & actual_no_churn).sum()\n",
    "\n",
    "confusion_matrix = np.array(\n",
    "     # predict neg    pos\n",
    "    [[true_negative, false_positive], # actual neg\n",
    "     [false_negative, true_positive]]) # actual pos\n",
    "\n",
    "printest('Confusion matrix', confusion_matrix)\n",
    "\n",
    "printest('Confusion matrix %', (confusion_matrix/confusion_matrix.sum()).round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs reasonably well in predicting negative outcomes, correctly identifying them 65% of the time. However, there are still areas for improvement, as some errors do occur. The model incorrectly predicts positive outcomes 9% of the time and also misses positive outcomes 11% of the time.\n",
    "\n",
    "| | Predicted False| Predicted True|\n",
    "|---| --- | --- | \n",
    "|Actual False| 1202 (65%)  | 172 (9%)|\n",
    "|Actual True| 197 (11%) | 289 (15%)|\n",
    "\n",
    "As we can see, the model could benefit from further refinement to reduce the number of false predictions and increase its overall accuracy. The values from the confusion table serve as the basis for many other evaluation metrics. For example, we can calculate accuracy as we did before:\n",
    "\n",
    "$$\\text{accuracy} = \\frac{(\\text{TN} + \\text{TP})}{\\text{TN} + \\text{TP} + \\text{FN} + \\text{FP}} = \\frac{1491}{1860} = 80\\%$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global metrics, like accuracy can be misleading when dealing with imbalanced\n",
    "datasets such as ours. Both precision and recall are calculated from the values of the confusion table. They both help us understand the quality of the model in cases of class imbalance. Remember:\n",
    "\n",
    "- **Precision**: Ratio of correct predictions out of all points that are predicted to belong to a class\n",
    "  \n",
    " $$\\text{prec}_i = \\frac{n_{ii}}{m_i} = \\left\\{ \\begin{array}{ll} \n",
    "\\frac{n_{00}}{m_{~-}} = \\frac{\\text{TN}}{\\text{TN}+\\text{FN}} \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{n_{11}}{m_{~+}} = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "where $m_i$ represents the total number of points that are predicted to belong to class $c_i$.\n",
    "\n",
    "- **Recall**: Ratio of correct predictions out of all points that actually belong to a class.\n",
    "\n",
    " $$\\text{recall}_i = \\frac{n_{ii}}{n_i} = \\left\\{ \\begin{array}{ll} \n",
    "\\frac{n_{00}}{n_{~-}} = \\frac{\\text{TN}}{\\text{TN}+\\text{FP}} \\\\\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{n_{11}}{n_{~+}} = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}}\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "where $n_i$ the total number of points that actually belong to class $c_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision TN : \n",
      " 0.627 \n",
      "\n",
      "recall TN : \n",
      " 0.595 \n",
      "\n",
      "precision TP : \n",
      " 0.859 \n",
      "\n",
      "recall TP : \n",
      " 0.875 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For true positive\n",
    "\n",
    "prec_tn = true_positive/(true_positive + false_positive)\n",
    "recall_tn = true_positive/(true_positive + false_negative)\n",
    "\n",
    "prec_tp = true_negative/(true_negative + false_negative)\n",
    "recall_tp = true_negative/(false_positive + true_negative)\n",
    "\n",
    "printest('precision TN',prec_tn.round(3) )\n",
    "printest('recall TN',recall_tn.round(3) )\n",
    "\n",
    "printest('precision TP',prec_tp.round(3) )\n",
    "printest('recall TP',recall_tp.round(3) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall are valuable metrics for understanding the effectiveness of our promotional messages.  Looking at the metrics in the table below:\n",
    "\n",
    "| Metrics | True Negative (TN) | True Positive (TP) |\n",
    "| --- | --- | --- |\n",
    "| Precision | 62% | 85% |\n",
    "| Recall | 59% | 87% |\n",
    " \n",
    "\n",
    "we can interpret them as follows:\n",
    "\n",
    "- **Precision (TN)**: On the other hand, a 62% precision for true negatives implies that of all the customers we predicted would stay, 62% indeed stayed. This suggests that our model is relatively good at predicting customers who won't churn, though it mistakenly categorized 38% of non-churners as churners.\n",
    "\n",
    "- **Precision (TP)**: Precision measures the quality of our predictions. A high precision score indicates a low false positive rate. Here, our precision of 85% for true positives suggests that out of all customers we predicted would churn, 85% actually did (true positives). However, it also means that 15% of our targeted customers were incorrectly identified as churners (false positives).\n",
    "\n",
    "- **Recall (TN)**: For true negatives, a recall of 59% means we correctly predicted 59% of customers who didn't churn. However, we wrongly identified 41% of these customers as churners.\n",
    "\n",
    "- **Recall (TP)**: Recall measures how well our model is doing at identifying all the cases we're interested in. A high recall score signifies a low false negative rate. Our model's recall score of 87% for true positives means we captured 87% of all potential churners. Regrettably, we didn't identify the remaining 13% who churned (false negatives).\n",
    "\n",
    "  \n",
    "The noticeable difference in precision and recall scores between true positives (churners) and true negatives (non-churners) is due to the imbalanced nature of our dataset. Because non-churners significantly outnumber churners, the model have more data to learn to correctly identify non-churners, resulting in higher precision and recall for the TP class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curve and AUC score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation of the performance of a binary classifier as the decision threshold is varied. Traditionally, we utilize a threshold of $t = 0.5$, as we did until now, but the ROC curve enables us to visualize the performance across all possible thresholds.\n",
    "\n",
    "In our churn prediction model, $P(Y|\\mathbf{x}_i) < t$ is the predicted probability of a customer retaining (not churning), whereas $P(Y|\\mathbf{x}_i) \\geq t$ is the predicted probability of a customer churning. Here, $t$ represents the different thresholds we will examine.\n",
    "\n",
    "The ROC curve represents the True Positive Rate (TPR) or sensitivity (y-axis) against the False Positive Rate (FPR) or 1-specificity (x-axis) as the decision threshold varies. Each point on the ROC curve corresponds to a unique pair of TPR and FPR values associated with a specific decision threshold.\n",
    "\n",
    "For each distinctive score, we plot a point with the coordinates:\n",
    "\n",
    "$$(FPR, TPR) = (1- \\text{specificity}, \\text{sensitivity})$$\n",
    "\n",
    "Remember that: \n",
    "    \n",
    "  - **False Positive Rate (FPR)**: Ratio of actual negative instances (i.e., customers who not churn) that are incorrectly identified as positive (i.e., predicted to churn)\n",
    "\n",
    "    $$1- \\text{specificity} = \\frac{ n_{01} } {n_{~+}} =  \\frac{ \\text{FP} }{\\text{FP} +\\text{TN} }$$\n",
    "  \n",
    "  - **True Positive Rate (Sensitivity)**: Ratio of actual positive instances (i.e., customers who churned) that are correctly identified as such.\n",
    "\n",
    "  $$\\text{recall}_{~+} = \\text{Sensitivity} = \\frac{n_{11}}{n_{~+}}  = \\frac{\\text{TP}}{\\text{TP} +\\text{FN}} $$\n",
    "\n",
    "**AUC Score**\n",
    "\n",
    "The Area Under the Curve (AUC) is a single, comprehensive metric that captures the complete performance of a binary classifier, as illustrated by the Receiver Operating Characteristic (ROC) curve.\n",
    "\n",
    "In our churn dataset scenario:\n",
    "\n",
    "- If the classifier predicts perfectly (i.e., every prediction matches the actual outcome), the ROC curve will stretch to the plot's top left corner, signifying an AUC score of 1. This condition also corresponds to an ideal situation where there's no overlap between the scores for the two classes, indicating perfect discrimination.\n",
    "\n",
    "- On the other hand, if a classifier cannot discriminate between the classes at all (i.e., it identifies equal numbers of false positives and true positives across all thresholds), the ROC curve will form a 45-degree diagonal line on the plot, which means the AUC is 0.5, an indication of random guessing.\n",
    "\n",
    "The advantage of the AUC-ROC metric is the reliable measure of the model's performance, regardless of whether your dataset is balanced (having an equal number of positive and negative instances) or imbalanced (containing a disproportionate number of either positive or negative instances). This robustness makes AUC-ROC an ideal choice for evaluating imbalanced classification problems, like customer churn prediction, where the number of negative outcomes (customers retaining their services) may significantly outnumber the positive ones (customers churning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>486</td>\n",
       "      <td>1374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>483</td>\n",
       "      <td>1190</td>\n",
       "      <td>3</td>\n",
       "      <td>184</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.866084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>481</td>\n",
       "      <td>1074</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.989712</td>\n",
       "      <td>0.781659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>478</td>\n",
       "      <td>1011</td>\n",
       "      <td>8</td>\n",
       "      <td>363</td>\n",
       "      <td>0.983539</td>\n",
       "      <td>0.735808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>478</td>\n",
       "      <td>970</td>\n",
       "      <td>8</td>\n",
       "      <td>404</td>\n",
       "      <td>0.983539</td>\n",
       "      <td>0.705968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp    fp  fn   tn       tpr       fpr\n",
       "0       0.00  486  1374   0    0  1.000000  1.000000\n",
       "1       0.01  483  1190   3  184  0.993827  0.866084\n",
       "2       0.02  481  1074   5  300  0.989712  0.781659\n",
       "3       0.03  478  1011   8  363  0.983539  0.735808\n",
       "4       0.04  478   970   8  404  0.983539  0.705968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds: #B\n",
    "    tp = ((y_pred >= t) & (y_val == 1)).sum()\n",
    "    fp = ((y_pred >= t) & (y_val == 0)).sum()\n",
    "    fn = ((y_pred < t) & (y_val == 1)).sum()\n",
    "    tn = ((y_pred < t) & (y_val == 0)).sum()\n",
    "    scores.append((t, tp, fp, fn, tn))\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores.columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "\n",
    "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n",
    "display(df_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(df_scores.threshold, df_scores.tpr, color='black', linestyle='solid', label='TPR')\n",
    "plt.plot(df_scores.threshold, df_scores.fpr, color='black', linestyle='dashed', label='FPR')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(np.linspace(0, 1, 11))\n",
    "plt.yticks(np.linspace(0, 1, 11))\n",
    "\n",
    "plt.xlabel('Thresholds')\n",
    "plt.title('TPR and FPR')\n",
    "\n",
    "# plt.savefig('04_fpr_tpr_plot.svg')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0743c798041383927c03f3bae5eca888e94e4777f716cdd511cdff96fbdedc02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
